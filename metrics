# complete_evaluation_system.py
# complete_evaluation_system.py
import numpy as np
import pandas as pd
import math
import pickle
import json
import warnings
import os
from typing import List, Dict, Set, Tuple, Any, Optional
from datetime import datetime
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report
warnings.filterwarnings('ignore')

class RecommendationSystemEvaluator:
    def __init__(self):
        self.train_data = None
        self.test_data = None
        self.submission_data = None
        self.relevance_dict = None
        self.model = None
        self.model_config = {}
        self.evaluation_results = {}
        self.items_df = None
        self.preprocessed_data = None

    def load_data(self, train_path: str = 'train.csv',
                  test_path: str = 'test.csv',
                  submission_path: str = 'submission.csv'):
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫

        Args:
            train_path: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É train.csv
            test_path: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É test.csv
            submission_path: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É submission.csv
        """
        print("üìÇ –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• –î–õ–Ø –í–´–ß–ò–°–õ–ï–ù–ò–Ø –ú–ï–¢–†–ò–ö...")

        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º train –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è ground truth
            self.train_data = pd.read_csv(train_path)
            print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.train_data)} –æ–±—É—á–∞—é—â–∏—Ö –ø–∞—Ä –∏–∑ {train_path}")

            # –ó–∞–≥—Ä—É–∂–∞–µ–º test –¥–∞–Ω–Ω—ã–µ
            self.test_data = pd.read_csv(test_path)
            print(f"üß™ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.test_data)} —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–∑ {test_path}")

            # –ó–∞–≥—Ä—É–∂–∞–µ–º submission (—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ–¥–µ–ª–∏)
            self.submission_data = pd.read_csv(submission_path)
            print(f"üìà –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.submission_data)} —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –∏–∑ {submission_path}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤
            if len(self.test_data) != len(self.submission_data):
                print(f"‚ö†Ô∏è  –í–Ω–∏–º–∞–Ω–∏–µ: test.csv —Å–æ–¥–µ—Ä–∂–∏—Ç {len(self.test_data)} –∑–∞–ø–∏—Å–µ–π, "
                      f"–∞ submission.csv —Å–æ–¥–µ—Ä–∂–∏—Ç {len(self.submission_data)} –∑–∞–ø–∏—Å–µ–π")

            return True

        except FileNotFoundError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–æ–≤: {e}")
            print("‚ö†Ô∏è  –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª—ã —Å—É—â–µ—Å—Ç–≤—É—é—Ç:")
            print(f"   - {train_path}")
            print(f"   - {test_path}")
            print(f"   - {submission_path}")
            return False
        except Exception as e:
            print(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return False

    def save_model(self, model: Any, model_name: str = 'recommendation_model',
                   config: Dict = None, output_dir: str = 'saved_models'):
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –≤ —Ñ–∞–π–ª –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

        Args:
            model: –æ–±—ä–µ–∫—Ç –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            model_name: –∏–º—è –º–æ–¥–µ–ª–∏
            config: –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
            output_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        """
        print(f"\nüíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ò '{model_name}'...")

        try:
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            os.makedirs(output_dir, exist_ok=True)

            # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            model_filename = f"{model_name}_{timestamp}.pkl"
            config_filename = f"{model_name}_config_{timestamp}.json"

            model_path = os.path.join(output_dir, model_filename)
            config_path = os.path.join(output_dir, config_filename)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
            with open(model_path, 'wb') as f:
                pickle.dump(model, f)
            print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {model_path}")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            if config:
                config['saved_timestamp'] = timestamp
                config['model_filename'] = model_filename
                with open(config_path, 'w') as f:
                    json.dump(config, f, indent=2)
                print(f"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {config_path}")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏ –≤ –∫–ª–∞—Å—Å–µ
            self.model = model
            self.model_config = config if config else {}
            self.model_config['save_path'] = model_path

            return model_path

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
            return None

    def load_model(self, model_path: str, config_path: Optional[str] = None):
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ —Ñ–∞–π–ª–∞

        Args:
            model_path: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –º–æ–¥–µ–ª–∏
            config_path: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        """
        print(f"\nü§ñ –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ò –ò–ó –§–ê–ô–õ–ê...")

        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
            with open(model_path, 'rb') as f:
                self.model = pickle.load(f)
            print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑: {model_path}")
            print(f"   –¢–∏–ø –º–æ–¥–µ–ª–∏: {type(self.model).__name__}")

            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞
            if config_path and os.path.exists(config_path):
                with open(config_path, 'r') as f:
                    self.model_config = json.load(f)
                print(f"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑: {config_path}")
            else:
                # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
                base_name = os.path.splitext(model_path)[0]
                config_candidates = [
                    config_path,
                    base_name + '_config.json',
                    base_name.replace('_model_', '_config_') + '.json'
                ]

                for candidate in config_candidates:
                    if candidate and os.path.exists(candidate):
                        with open(candidate, 'r') as f:
                            self.model_config = json.load(f)
                        print(f"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑: {candidate}")
                        break
                else:
                    print("‚ö†Ô∏è  –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                    self.model_config = {'model_path': model_path}

            return True

        except FileNotFoundError:
            print(f"‚ùå –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {model_path}")
            return False
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            return False

    def load_preprocessed_data(self, preprocessed_path: str = 'preprocessed_data.pkl'):
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

        Args:
            preprocessed_path: –ø—É—Ç—å –∫ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º –¥–∞–Ω–Ω—ã–º
        """
        print("\nüìä –ó–ê–ì–†–£–ó–ö–ê –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ê–ù–ù–´–• –î–ê–ù–ù–´–•...")

        try:
            with open(preprocessed_path, 'rb') as f:
                self.preprocessed_data = pickle.load(f)
                print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω—ã –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ {preprocessed_path}")

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                if 'items_df' in self.preprocessed_data:
                    self.items_df = self.preprocessed_data['items_df']
                    print(f"   - –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.items_df)} –æ–±—ä–µ–∫—Ç–æ–≤")

                if 'relevance_pairs' in self.preprocessed_data:
                    self.relevance_pairs = self.preprocessed_data['relevance_pairs']
                    print(f"   - –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.relevance_pairs)} –ø–∞—Ä —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏")

                if 'item_popularity' in self.preprocessed_data:
                    self.item_popularity = self.preprocessed_data['item_popularity']
                    print(f"   - –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.item_popularity)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏")

            return True

        except FileNotFoundError:
            print(f"‚ö†Ô∏è  –§–∞–π–ª –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω: {preprocessed_path}")
            return False
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
            return False

    def create_relevance_dict(self) -> Dict[str, Set[str]]:
        """
        –°–æ–∑–¥–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∏–∑ train –¥–∞–Ω–Ω—ã—Ö

        Returns:
            –°–ª–æ–≤–∞—Ä—å {query_id: set(relevant_item_ids)}
        """
        print("\nüîç –°–û–ó–î–ê–ù–ò–ï –°–õ–û–í–ê–†–Ø –†–ï–õ–ï–í–ê–ù–¢–ù–û–°–¢–ò...")

        if self.train_data is None:
            raise ValueError("Train –¥–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")

        self.relevance_dict = {}

        for _, row in self.train_data.iterrows():
            query_id = str(row['query_id'])
            item_id = str(row['item_id'])

            if query_id not in self.relevance_dict:
                self.relevance_dict[query_id] = set()
            self.relevance_dict[query_id].add(item_id)

        print(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(self.relevance_dict)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ —Å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        rel_counts = [len(items) for items in self.relevance_dict.values()]
        print(f"üìä –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ –∑–∞–ø—Ä–æ—Å: {np.mean(rel_counts):.2f}")
        print(f"üìà –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤: {max(rel_counts)}")
        print(f"üìâ –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤: {min(rel_counts)}")

        return self.relevance_dict

    def calculate_all_metrics(self, k_values: List[int] = [1, 3, 5, 10]) -> Dict[str, Any]:
        """
        –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞

        Args:
            k_values: —Å–ø–∏—Å–æ–∫ –∑–Ω–∞—á–µ–Ω–∏–π k –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ –≤—Å–µ–º–∏ –≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
        """
        print("\nüìà –í–´–ß–ò–°–õ–ï–ù–ò–ï –í–°–ï–• –ú–ï–¢–†–ò–ö –ö–ê–ß–ï–°–¢–í–ê...")

        if self.relevance_dict is None:
            self.create_relevance_dict()

        metrics = {
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'total_test_queries': len(self.test_data),
            'total_train_pairs': len(self.train_data),
            'k_values': k_values
        }

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä –¥–ª—è –º–µ—Ç—Ä–∏–∫
        accuracy_results = {k: {'correct': 0, 'total': 0} for k in k_values}
        precision_results = {k: [] for k in k_values}
        recall_results = {k: [] for k in k_values}
        ndcg_results = {k: [] for k in k_values}
        map_results = {k: [] for k in k_values}
        query_details = []

        processed_queries = 0

        for idx, test_row in self.test_data.iterrows():
            query_id = str(test_row['id'])

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ –Ω–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –∏–ª–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
            if idx >= len(self.submission_data) or query_id not in self.relevance_dict:
                continue

            # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            rec_items = self.submission_data.iloc[idx]['relevant_item_id_list']
            if isinstance(rec_items, str):
                recommended = rec_items.split()
            else:
                recommended = []

            # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
            relevant = self.relevance_dict[query_id]

            query_metrics = {
                'query_id': query_id,
                'num_relevant': len(relevant),
                'num_recommended': len(recommended)
            }

            # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ k
            for k in k_values:
                # –ë–µ—Ä–µ–º —Ç–æ–ø-k —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
                top_k = recommended[:k]

                # Accuracy@k
                found_relevant = any(item in relevant for item in top_k)
                accuracy_results[k]['correct'] += 1 if found_relevant else 0
                accuracy_results[k]['total'] += 1

                # Precision@k –∏ Recall@k
                tp = sum(1 for item in top_k if item in relevant)
                precision = tp / len(top_k) if len(top_k) > 0 else 0
                recall = tp / len(relevant) if len(relevant) > 0 else 0

                precision_results[k].append(precision)
                recall_results[k].append(recall)

                # nDCG@k
                rel_scores = [1 if item in relevant else 0 for item in top_k]
                while len(rel_scores) < k:
                    rel_scores.append(0)

                dcg = sum(score / math.log2(i + 2) for i, score in enumerate(rel_scores[:k]))

                num_relevant_k = min(len(relevant), k)
                ideal_scores = [1] * num_relevant_k + [0] * (k - num_relevant_k)
                idcg = sum(score / math.log2(i + 2) for i, score in enumerate(ideal_scores))

                ndcg = dcg / idcg if idcg > 0 else 0
                ndcg_results[k].append(ndcg)

                # AP@k –¥–ª—è MAP
                running_sum = 0
                num_relevant_found = 0

                for i, item in enumerate(top_k):
                    if item in relevant:
                        num_relevant_found += 1
                        precision_at_i = num_relevant_found / (i + 1)
                        running_sum += precision_at_i

                ap = running_sum / len(relevant) if len(relevant) > 0 else 0
                map_results[k].append(ap)

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —ç—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
                query_metrics[f'accuracy@{k}'] = 1 if found_relevant else 0
                query_metrics[f'precision@{k}'] = precision
                query_metrics[f'recall@{k}'] = recall
                query_metrics[f'ndcg@{k}'] = ndcg
                query_metrics[f'ap@{k}'] = ap
                query_metrics[f'found@{k}'] = tp

            query_details.append(query_metrics)
            processed_queries += 1

            # –ü—Ä–æ–≥—Ä–µ—Å—Å
            if processed_queries % 100 == 0:
                print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_queries} –∑–∞–ø—Ä–æ—Å–æ–≤...")

        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
        final_metrics = {}

        for k in k_values:
            # Accuracy@k
            if accuracy_results[k]['total'] > 0:
                accuracy = accuracy_results[k]['correct'] / accuracy_results[k]['total']
            else:
                accuracy = 0

            # Precision@k
            precision_avg = np.mean(precision_results[k]) if precision_results[k] else 0

            # Recall@k
            recall_avg = np.mean(recall_results[k]) if recall_results[k] else 0

            # nDCG@k
            ndcg_avg = np.mean(ndcg_results[k]) if ndcg_results[k] else 0

            # MAP@k
            map_avg = np.mean(map_results[k]) if map_results[k] else 0

            # F1-Score@k
            f1 = 2 * precision_avg * recall_avg / (precision_avg + recall_avg + 1e-8)

            final_metrics[f'accuracy@{k}'] = accuracy
            final_metrics[f'precision@{k}'] = precision_avg
            final_metrics[f'recall@{k}'] = recall_avg
            final_metrics[f'f1@{k}'] = f1
            final_metrics[f'ndcg@{k}'] = ndcg_avg
            final_metrics[f'map@{k}'] = map_avg

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        coverage_stats = self._calculate_coverage_statistics()

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self.evaluation_results = {
            'metrics': final_metrics,
            'query_details': query_details,
            'coverage_stats': coverage_stats,
            'processed_queries': processed_queries,
            'accuracy_raw': accuracy_results,
            'precision_raw': precision_results,
            'recall_raw': recall_results,
            'ndcg_raw': ndcg_results,
            'map_raw': map_results
        }

        # –í—ã–≤–æ–¥–∏–º –æ—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self._print_metrics_summary(k_values)

        return self.evaluation_results

    def _calculate_coverage_statistics(self) -> Dict[str, Any]:
        """
        –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ–∫—Ä—ã—Ç–∏—è
        """
        print("\nüìä –í–´–ß–ò–°–õ–ï–ù–ò–ï –°–¢–ê–¢–ò–°–¢–ò–ö–ò –ü–û–ö–†–´–¢–ò–Ø...")

        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã –≤ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è—Ö
        all_recommended_items = set()
        recommendation_counts = []

        for idx, row in self.submission_data.iterrows():
            rec_items = row['relevant_item_id_list']
            if isinstance(rec_items, str):
                items = rec_items.split()
                all_recommended_items.update(items)
                recommendation_counts.append(len(items))

        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã –≤ train
        all_train_items = set()
        if self.relevance_dict:
            for items in self.relevance_dict.values():
                all_train_items.update(items)

        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø–æ–∫—Ä—ã—Ç–∏—è
        coverage_stats = {
            'unique_items_in_train': len(all_train_items),
            'unique_items_recommended': len(all_recommended_items),
            'item_coverage': len(all_recommended_items) / len(all_train_items) if len(all_train_items) > 0 else 0,
            'avg_recommendations_per_query': np.mean(recommendation_counts) if recommendation_counts else 0,
            'std_recommendations_per_query': np.std(recommendation_counts) if recommendation_counts else 0,
            'max_recommendations_per_query': max(recommendation_counts) if recommendation_counts else 0,
            'min_recommendations_per_query': min(recommendation_counts) if recommendation_counts else 0,
            'median_recommendations_per_query': np.median(recommendation_counts) if recommendation_counts else 0,
            'recommendation_distribution': pd.Series(recommendation_counts).value_counts().to_dict()
        }

        print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –≤ train: {coverage_stats['unique_items_in_train']}")
        print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –≤ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è—Ö: {coverage_stats['unique_items_recommended']}")
        print(f"   –ü–æ–∫—Ä—ã—Ç–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤: {coverage_stats['item_coverage']:.2%}")
        print(f"   –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {coverage_stats['avg_recommendations_per_query']:.2f}")

        return coverage_stats

    def _print_metrics_summary(self, k_values: List[int]):
        """
        –í—ã–≤–æ–¥ —Å–≤–æ–¥–∫–∏ –º–µ—Ç—Ä–∏–∫
        """
        print("\n" + "="*60)
        print("üìä –°–í–û–î–ö–ê –ú–ï–¢–†–ò–ö –ö–ê–ß–ï–°–¢–í–ê")
        print("="*60)

        metrics = self.evaluation_results['metrics']

        for k in k_values:
            print(f"\nüìç k = {k}:")
            print(f"   Accuracy@{k}:   {metrics.get(f'accuracy@{k}', 0):.4f}")
            print(f"   Precision@{k}:  {metrics.get(f'precision@{k}', 0):.4f}")
            print(f"   Recall@{k}:     {metrics.get(f'recall@{k}', 0):.4f}")
            print(f"   F1-Score@{k}:   {metrics.get(f'f1@{k}', 0):.4f}")
            print(f"   nDCG@{k}:       {metrics.get(f'ndcg@{k}', 0):.4f}")
            print(f"   MAP@{k}:        {metrics.get(f'map@{k}', 0):.4f}")

        print(f"\nüìà –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {self.evaluation_results['processed_queries']}")
        print(f"üìä –ü–æ–∫—Ä—ã—Ç–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤: {self.evaluation_results['coverage_stats']['item_coverage']:.2%}")

    def save_evaluation_results(self, output_dir: str = 'evaluation_results',
                               model_name: str = 'model'):
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ü–µ–Ω–∫–∏

        Args:
            output_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            model_name: –∏–º—è –º–æ–¥–µ–ª–∏
        """
        print(f"\nüíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –û–¶–ï–ù–ö–ò...")

        try:
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            os.makedirs(output_dir, exist_ok=True)

            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

            # 1. –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ JSON
            metrics_file = os.path.join(output_dir, f'{model_name}_metrics_{timestamp}.json')

            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            save_data = {
                'model_info': {
                    'name': model_name,
                    'evaluation_timestamp': self.evaluation_results.get('timestamp', ''),
                    'model_config': self.model_config
                },
                'dataset_info': {
                    'train_size': len(self.train_data) if self.train_data is not None else 0,
                    'test_size': len(self.test_data) if self.test_data is not None else 0,
                    'processed_queries': self.evaluation_results.get('processed_queries', 0)
                },
                'metrics': self.evaluation_results.get('metrics', {}),
                'coverage_stats': self.evaluation_results.get('coverage_stats', {})
            }

            with open(metrics_file, 'w') as f:
                json.dump(save_data, f, indent=2, default=str)
            print(f"‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {metrics_file}")

            # 2. –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª–∏ –ø–æ –∑–∞–ø—Ä–æ—Å–∞–º –≤ CSV
            if 'query_details' in self.evaluation_results:
                details_file = os.path.join(output_dir, f'{model_name}_query_details_{timestamp}.csv')
                details_df = pd.DataFrame(self.evaluation_results['query_details'])
                details_df.to_csv(details_file, index=False)
                print(f"‚úÖ –î–µ—Ç–∞–ª–∏ –ø–æ –∑–∞–ø—Ä–æ—Å–∞–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {details_file}")

            # 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç –≤ TXT
            report_file = os.path.join(output_dir, f'{model_name}_report_{timestamp}.txt')
            self._generate_text_report(report_file, save_data)
            print(f"‚úÖ –¢–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {report_file}")

            # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            try:
                self._generate_visualizations(output_dir, model_name, timestamp)
            except Exception as e:
                print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")

            # 5. –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∑–∞–ø—É—Å–∫–∞
            config_file = os.path.join(output_dir, f'{model_name}_evaluation_config_{timestamp}.json')
            run_config = {
                'evaluation_date': timestamp,
                'model_name': model_name,
                'train_file': 'train.csv',
                'test_file': 'test.csv',
                'submission_file': 'submission.csv',
                'k_values': list(self.evaluation_results.get('metrics', {}).keys())
            }

            with open(config_file, 'w') as f:
                json.dump(run_config, f, indent=2)

            print(f"\nüéâ –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {output_dir}/")

            return {
                'metrics_file': metrics_file,
                'report_file': report_file
            }

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")
            return None

    def _generate_text_report(self, filepath: str, data: Dict):
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞
        """
        with open(filepath, 'w') as f:
            f.write("="*70 + "\n")
            f.write("–û–¢–ß–ï–¢ –ü–û –û–¶–ï–ù–ö–ï –†–ï–ö–û–ú–ï–ù–î–ê–¢–ï–õ–¨–ù–û–ô –°–ò–°–¢–ï–ú–´\n")
            f.write("="*70 + "\n\n")

            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
            f.write("–ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ú–û–î–ï–õ–ò:\n")
            f.write("-"*40 + "\n")
            f.write(f"–ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏: {data['model_info']['name']}\n")
            f.write(f"–î–∞—Ç–∞ –æ—Ü–µ–Ω–∫–∏: {data['model_info']['evaluation_timestamp']}\n\n")

            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö
            f.write("–ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –î–ê–ù–ù–´–•:\n")
            f.write("-"*40 + "\n")
            f.write(f"–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {data['dataset_info']['train_size']}\n")
            f.write(f"–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: {data['dataset_info']['test_size']}\n")
            f.write(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {data['dataset_info']['processed_queries']}\n\n")

            # –ú–µ—Ç—Ä–∏–∫–∏
            f.write("–ú–ï–¢–†–ò–ö–ò –ö–ê–ß–ï–°–¢–í–ê:\n")
            f.write("-"*40 + "\n")

            metrics = data['metrics']
            for metric_name, value in metrics.items():
                f.write(f"{metric_name:20}: {value:.4f}\n")

            f.write("\n")

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–∫—Ä—ã—Ç–∏—è
            f.write("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û–ö–†–´–¢–ò–Ø:\n")
            f.write("-"*40 + "\n")
            coverage = data['coverage_stats']
            f.write(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –≤ train: {coverage['unique_items_in_train']}\n")
            f.write(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –≤ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è—Ö: {coverage['unique_items_recommended']}\n")
            f.write(f"–ü–æ–∫—Ä—ã—Ç–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤: {coverage['item_coverage']:.2%}\n")
            f.write(f"–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –∑–∞–ø—Ä–æ—Å: {coverage['avg_recommendations_per_query']:.2f}\n")
            f.write(f"–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {coverage['std_recommendations_per_query']:.2f}\n")

            f.write("\n" + "="*70 + "\n")
            f.write("–ö–û–ù–ï–¶ –û–¢–ß–ï–¢–ê\n")
            f.write("="*70 + "\n")

    def _generate_visualizations(self, output_dir: str, model_name: str, timestamp: str):
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π –º–µ—Ç—Ä–∏–∫
        """
        if not self.evaluation_results:
            return

        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
        plots_dir = os.path.join(output_dir, 'plots')
        os.makedirs(plots_dir, exist_ok=True)

        metrics = self.evaluation_results['metrics']

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è k –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏–π –º–µ—Ç—Ä–∏–∫
        k_values = sorted(set(int(k.split('@')[1]) for k in metrics.keys() if '@' in k))

        if not k_values:
            return

        # 1. –ì—Ä–∞—Ñ–∏–∫ –º–µ—Ç—Ä–∏–∫ –ø–æ —Ä–∞–∑–Ω—ã–º k
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        axes = axes.flatten()

        metric_types = ['accuracy', 'precision', 'recall', 'f1', 'ndcg', 'map']

        for idx, metric_type in enumerate(metric_types):
            ax = axes[idx]
            values = []
            ks = []

            for k in k_values:
                metric_key = f'{metric_type}@{k}'
                if metric_key in metrics:
                    values.append(metrics[metric_key])
                    ks.append(k)

            if values:
                ax.plot(ks, values, marker='o', linewidth=2, markersize=8)
                ax.set_title(f'{metric_type.upper()} –ø–æ —Ä–∞–∑–Ω—ã–º k', fontsize=12, fontweight='bold')
                ax.set_xlabel('k')
                ax.set_ylabel(metric_type)
                ax.grid(True, alpha=0.3)
                ax.set_ylim(0, 1.05)

                # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Ç–æ—á–∫–∞—Ö
                for x, y in zip(ks, values):
                    ax.text(x, y + 0.02, f'{y:.3f}', ha='center', fontsize=9)

        plt.tight_layout()
        plot_path = os.path.join(plots_dir, f'{model_name}_metrics_by_k_{timestamp}.png')
        plt.savefig(plot_path, dpi=150, bbox_inches='tight')
        plt.close()

        # 2. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ nDCG@10
        if 'ndcg_raw' in self.evaluation_results and 10 in self.evaluation_results['ndcg_raw']:
            ndcg_values = self.evaluation_results['ndcg_raw'][10]

            plt.figure(figsize=(10, 6))
            plt.hist(ndcg_values, bins=20, alpha=0.7, color='skyblue', edgecolor='black')
            plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ nDCG@10 –ø–æ –∑–∞–ø—Ä–æ—Å–∞–º', fontsize=14, fontweight='bold')
            plt.xlabel('nDCG@10')
            plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤')
            plt.grid(True, alpha=0.3)

            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            mean_val = np.mean(ndcg_values)
            median_val = np.median(ndcg_values)
            plt.axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'–°—Ä–µ–¥–Ω–µ–µ: {mean_val:.3f}')
            plt.axvline(median_val, color='green', linestyle='--', linewidth=2, label=f'–ú–µ–¥–∏–∞–Ω–∞: {median_val:.3f}')
            plt.legend()

            plot_path2 = os.path.join(plots_dir, f'{model_name}_ndcg_distribution_{timestamp}.png')
            plt.savefig(plot_path2, dpi=150, bbox_inches='tight')
            plt.close()

        print(f"‚úÖ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {plots_dir}/")

    def create_model_card(self, model_info: Dict = None, output_dir: str = 'model_cards'):
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—Ä—Ç–æ—á–∫–∏ –º–æ–¥–µ–ª–∏ (Model Card)

        Args:
            model_info: –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
            output_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        """
        print(f"\nüìã –°–û–ó–î–ê–ù–ò–ï –ö–ê–†–¢–û–ß–ö–ò –ú–û–î–ï–õ–ò...")

        try:
            os.makedirs(output_dir, exist_ok=True)

            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            model_card_path = os.path.join(output_dir, f'model_card_{timestamp}.md')

            with open(model_card_path, 'w') as f:
                f.write("# –ö–∞—Ä—Ç–æ—á–∫–∞ –º–æ–¥–µ–ª–∏ (Model Card)\n\n")

                # –ú–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                f.write("## –ú–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è\n")
                f.write(f"- **–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:** {timestamp}\n")
                f.write(f"- **–¢–∏–ø –º–æ–¥–µ–ª–∏:** –†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞\n")
                f.write(f"- **–ó–∞–¥–∞—á–∞:** –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –º—É–∑–µ–π–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤\n\n")

                # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö
                f.write("## –î–∞–Ω–Ω—ã–µ\n")
                f.write(f"- **–û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞:** {len(self.train_data)} –ø–∞—Ä\n")
                f.write(f"- **–¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞:** {len(self.test_data)} –∑–∞–ø—Ä–æ—Å–æ–≤\n")
                f.write(f"- **–†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è –æ–±—ä–µ–∫—Ç–æ–≤:** {len(set().union(*self.relevance_dict.values()))}\n\n")

                # –ú–µ—Ç—Ä–∏–∫–∏
                f.write("## –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞\n")
                f.write("| –ú–µ—Ç—Ä–∏–∫–∞ | –ó–Ω–∞—á–µ–Ω–∏–µ |\n")
                f.write("|---------|----------|\n")

                metrics = self.evaluation_results.get('metrics', {})
                for metric_name, value in sorted(metrics.items()):
                    f.write(f"| {metric_name} | {value:.4f} |\n")

                f.write("\n")

                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–∫—Ä—ã—Ç–∏—è
                coverage = self.evaluation_results.get('coverage_stats', {})
                f.write("## –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–∫—Ä—ã—Ç–∏—è\n")
                f.write(f"- **–ü–æ–∫—Ä—ã—Ç–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤:** {coverage.get('item_coverage', 0):.2%}\n")
                f.write(f"- **–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ:** {coverage.get('unique_items_recommended', 0)}\n")
                f.write(f"- **–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π:** {coverage.get('avg_recommendations_per_query', 0):.2f}\n\n")

                # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
                if self.model_config:
                    f.write("## –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏\n")
                    f.write("```json\n")
                    f.write(json.dumps(self.model_config, indent=2, default=str))
                    f.write("\n```\n\n")

                # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
                f.write("## –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é\n")
                f.write("- –ú–æ–¥–µ–ª—å –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω–∞ –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –º—É–∑–µ–π–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤\n")
                f.write("- –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: 10\n")
                f.write("- –ú–æ–¥–µ–ª—å —É—á–∏—Ç—ã–≤–∞–µ—Ç –º–æ–¥–∞–ª—å–Ω–æ—Å—Ç—å –æ–±—ä–µ–∫—Ç–æ–≤\n")
                f.write("- –î–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ–±–Ω–æ–≤–ª—è—Ç—å –¥–∞–Ω–Ω—ã–µ\n")

            print(f"‚úÖ –ö–∞—Ä—Ç–æ—á–∫–∞ –º–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {model_card_path}")

            return model_card_path

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∫–∞—Ä—Ç–æ—á–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            return None

def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
    """
    print("üéØ –ü–û–õ–ù–ê–Ø –°–ò–°–¢–ï–ú–ê –û–¶–ï–ù–ö–ò –ò –°–û–•–†–ê–ù–ï–ù–ò–Ø –ú–û–î–ï–õ–ò")
    print("="*70)

    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    CONFIG = {
        'train_path': 'train.csv',
        'test_path': 'test.csv',
        'submission_path': 'submission.csv',
        'model_path': 'model.pkl',  # –î–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –º–æ–¥–µ–ª–∏
        'preprocessed_path': 'preprocessed_data.pkl',
        'k_values': [1, 3, 5, 10],
        'model_name': 'museum_recommender',
        'output_dir': 'evaluation_results'
    }

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ü–µ–Ω—â–∏–∫–∞
    evaluator = RecommendationSystemEvaluator()

    try:
        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        print("\n1Ô∏è‚É£  –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•")
        if not evaluator.load_data(CONFIG['train_path'], CONFIG['test_path'], CONFIG['submission_path']):
            return

        # 2. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        print("\n2Ô∏è‚É£  –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ò")
        if os.path.exists(CONFIG['model_path']):
            evaluator.load_model(CONFIG['model_path'])
        else:
            print("‚ö†Ô∏è  –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏.")

        # 3. –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–µ—Å–ª–∏ –µ—Å—Ç—å)
        print("\n3Ô∏è‚É£  –ó–ê–ì–†–£–ó–ö–ê –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ê–ù–ù–´–• –î–ê–ù–ù–´–•")
        if os.path.exists(CONFIG['preprocessed_path']):
            evaluator.load_preprocessed_data(CONFIG['preprocessed_path'])
        else:
            print("‚ö†Ô∏è  –§–∞–π–ª –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω.")

        # 4. –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        print("\n4Ô∏è‚É£  –í–´–ß–ò–°–õ–ï–ù–ò–ï –ú–ï–¢–†–ò–ö")
        results = evaluator.calculate_all_metrics(k_values=CONFIG['k_values'])

        # 5. –ü—Ä–∏–º–µ—Ä —Å–æ–∑–¥–∞–Ω–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
        print("\n5Ô∏è‚É£  –°–û–•–†–ê–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ò")

        # –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–º–µ—Ä –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        example_model = {
            'type': 'recommendation_system',
            'metrics': results['metrics'],
            'config': {
                'k_values': CONFIG['k_values'],
                'model_name': CONFIG['model_name'],
                'evaluation_date': datetime.now().strftime('%Y-%m-%d')
            }
        }

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
        saved_model_path = evaluator.save_model(
            model=example_model,
            model_name=CONFIG['model_name'],
            config=example_model['config'],
            output_dir='saved_models'
        )

        # 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ü–µ–Ω–∫–∏
        print("\n6Ô∏è‚É£  –°–û–•–†–ê–ù–ï–ù–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –û–¶–ï–ù–ö–ò")
        saved_results = evaluator.save_evaluation_results(
            output_dir=CONFIG['output_dir'],
            model_name=CONFIG['model_name']
        )

        # 7. –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—Ä—Ç–æ—á–∫–∏ –º–æ–¥–µ–ª–∏
        print("\n7Ô∏è‚É£  –°–û–ó–î–ê–ù–ò–ï –ö–ê–†–¢–û–ß–ö–ò –ú–û–î–ï–õ–ò")
        model_card_path = evaluator.create_model_card(
            model_info={
                'name': CONFIG['model_name'],
                'description': '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –º—É–∑–µ–π–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤',
                'author': '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞',
                'version': '1.0'
            },
            output_dir='model_cards'
        )

        # 8. –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
        print("\n" + "="*70)
        print("üéâ –û–¶–ï–ù–ö–ê –ò –°–û–•–†–ê–ù–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–´!")
        print("="*70)

        print(f"\nüìÅ –°–û–•–†–ê–ù–ï–ù–ù–´–ï –§–ê–ô–õ–´:")
        print(f"   üìä –ú–æ–¥–µ–ª—å: {saved_model_path}")
        print(f"   üìà –ú–µ—Ç—Ä–∏–∫–∏: {saved_results['metrics_file'] if saved_results else '–ù–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã'}")
        print(f"   üìã –û—Ç—á–µ—Ç: {saved_results['report_file'] if saved_results else '–ù–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω'}")
        print(f"   üìÑ –ö–∞—Ä—Ç–æ—á–∫–∞ –º–æ–¥–µ–ª–∏: {model_card_path}")

        # –í—ã–≤–æ–¥ –∫–ª—é—á–µ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫
        print(f"\nüèÜ –ö–õ–Æ–ß–ï–í–´–ï –ú–ï–¢–†–ò–ö–ò:")
        metrics = results['metrics']
        print(f"   Accuracy@10:   {metrics.get('accuracy@10', 0):.4f}")
        print(f"   Precision@10:  {metrics.get('precision@10', 0):.4f}")
        print(f"   Recall@10:     {metrics.get('recall@10', 0):.4f}")
        print(f"   F1-Score@10:   {metrics.get('f1@10', 0):.4f}")
        print(f"   nDCG@10:       {metrics.get('ndcg@10', 0):.4f}")
        print(f"   MAP@10:        {metrics.get('map@10', 0):.4f}")

        print(f"\nüìä –ü–û–ö–†–´–¢–ò–ï:")
        coverage = results['coverage_stats']
        print(f"   –û–±—ä–µ–∫—Ç–æ–≤ –≤ train: {coverage['unique_items_in_train']}")
        print(f"   –û–±—ä–µ–∫—Ç–æ–≤ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ: {coverage['unique_items_recommended']}")
        print(f"   –ü–æ–∫—Ä—ã—Ç–∏–µ: {coverage['item_coverage']:.2%}")

    except Exception as e:
        print(f"\nüí• –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
